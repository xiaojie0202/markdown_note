# 机器学习算法分类
>- 监督学习
>>- 分类： k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络
>>- 回归: 线性回归、岭回归
>>- 标注： 隐马尔可夫模型
>- 无监督学习
>>- 聚类    k-means
# 估计器
    在sklearn中，估计器(estimator)是一个重要的角色，分类器和回归器都属于estimator，是一类实现了算法的API
1. 用于分类的估计器：
>- sklearn.neighbors	k-近邻算法
>- sklearn.naive_bayes      贝叶斯
>- sklearn.linear_model.LogisticRegression     逻辑回归
2. 用于回归的估计器：
>- sklearn.linear_model.LinearRegression     线性回归
>- sklearn.linear_model.Ridge      岭回归 
## 估计器的工作流程
![](https://note.youdao.com/yws/public/resource/4d9f2b353221035aa2dc87736c84e628/xmlnote/A4294BB53BE84724BC772F4FEF5CBDE7/7591)

# 监督学习
    监督学习（英语：Supervised learning），可以由输入数据中学
    到或建立一个模型，并依此模式推测新的结果。输入数据是由
    输入特征值和目标值所组成。函数的输出可以是一个连续的值
    （称为回归），或是输出是有限个离散值（称作分类）。
## 分类
    判别分类算法的依据是目标值是离散型
    分类是监督学习的一个核心问题，在监督学习中，当输出变量取有限个离散值时，预测问题变成为分类问题。最基础的便是二分类问题，即判断是非，从两个类别中选择一个作为预测结果；
>- 分类在于根据其特性将数据“分门别类”，所以在许多领域都有广泛的应用
>>- 在银行业务中，构建一个客户分类模型，按客户按照贷款风险的大小进行分类
>>- 图像处理中，分类可以用来检测图像中是否有人脸出现，动物类别等
>>- 手写识别中，分类可以用于识别手写的数字
>>- 文本分类，这里的文本可以是新闻报道、网页、电子邮件、学术论文
### K-近邻算法
    用来对数据进行分类，核心原理是通过算法计算未知分类的数据与已知分类的数据的距离，最近的则是该数据的分类
1. 算法原理

![](https://note.youdao.com/yws/public/resource/4d9f2b353221035aa2dc87736c84e628/xmlnote/1BD966C69ADB4BE3B5CB14EC91EEBCA7/7593)

2. 算法案例
    
![](https://note.youdao.com/yws/public/resource/4d9f2b353221035aa2dc87736c84e628/xmlnote/36C947FDC5D34FDBA1E251E1CCD2BB1C/7595)
#### K-近邻算法API
    sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm='auto')
1. 参数详解
>- n_neighbors
>>- n_neighbors：int,可选（默认= 5），k_neighbors查询默认使用的邻居数 

>- algorithm
>>- algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)
2. 方法

3. 实例
```python
"""
案例分析：
    根据用户的位置，定位准确性，时间戳，来预测用户入住位置
数据:
    ./data/train.csv
        row_id:登记事件的ID
        x,y    ： 坐标
        accuracy ： 定位准确性
        time     ：  时间戳
        place_id ：入住的位置ID
分析：
    特征值 ： （x, y, accuracy, time）  目标值(place_id)
"""
from sklearn.preprocessing import StandardScaler  # 标准化
from sklearn.neighbors import KNeighborsClassifier # K-近邻算法估计器
from sklearn.model_selection import train_test_split # 数据集划分
import pandas as pd

# 读取csv数据集，进行处理
data = pd.read_csv('train.csv', usecols=['x', 'y', 'accuracy', 'time', 'place_id'])
# 目标值
x = data['place_id']
# 特征值
y = data.drop(['place_id'],axis=1)

# 进行数据集划分
x_train, x_test, y_train, y_test = train_test_split(y, x, test_size=0.25)

std = StandardScaler()
x_train = std.fit_transform(x_train) # 训练集的特征值做标准化
x_test = std.transform(x_test) # 测试集的特征值做标准版

# 进行训练算法
knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(x_train, y_train) # 把数据输入到算法中

# 预测结果
y_predict = knn.predict(x_test)
print(y_predict)

# 计算准确率
print('准确率:', knn.score(x_test, y_test))
```

```python
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd

# 鸢尾花
data = load_iris()
print(data.target_names)  # ['setosa' 'versicolor' 'virginica']， 花的名称
x = pd.DataFrame(data.data)
y = pd.DataFrame(data.target)


# 把数据划分成训练集个测试集
x_train, x_test, y_train, y_test = train_test_split(x, y)


# 对数据进行标准化处理
std = StandardScaler()
x_train = std.fit_transform(x_train)
x_test = std.transform(x_test)

# 把数据输入到算法中进行训练
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)

predict = knn.predict(x_test) # 预测测试集数据
print(predict)

# 查看准确率
print(knn.score(x_test, y_test))
```
### 朴素贝叶斯算法
## 回归
    回归是监督学习的另一个重要问题。回归用于预测输入变量和输出变量之间的关系，输出是连续型的值。
>- 回归在多领域也有广泛的应用
>>- 房价预测，根据某地历史房价数据，进行一个预测
>>- 金融信息，每日股票走向


# 无监督学习
    无监督学习（英语：Supervised learning），可以由输入数据中
    学到或建立一个模型，并依此模式推测新的结果。输入数据是
    由输入特征值所组成。



 