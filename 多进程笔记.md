# 进程
>由于GIL问题存在，python中多线程其实并不是真正的多线程，如果想要重复利用多核CPU资源则需要使用进程

## 多进程模块 multiprocessing
>multiprocessing包是Python中的多进程管理包。与threading.Thread类似，它可以利用multiprocessing.Process对象来创建一个进程。该进程可以运行在Python程序内部编写的函数。该Process对象与Thread对象的用法相同，也有start(), run(), join()的方法。此外multiprocessing包中也有Lock/Event/Semaphore/Condition类 (这些对象可以像多线程那样，通过参数传递给各个进程)，用以同步进程，其用法与threading包中的同名类一致。所以，multiprocessing的很大一部份与threading使用同一套API，只不过换到了多进程的情境。

>注意：由于进程之间的数据需要各自持有一份，所以创建进程需要的非常大的开销。

## multiprocessing模块详解
### Process
>- multiprocessing.Process(target=None, name=None, args=(), kwargs={})
>>- target:表示这个进程实例所调用对象；
>>- name:为当前进程实例的别名；
>>- args：表示调用对象的位置参数元组；
>>- kwargs：表示调用对象的关键字参数字典；
>- is_alive()：判断进程实例是否还在执行；
>- join([timeout])：是否等待进程实例执行结束，或等待多少秒；
>- start()：启动进程实例（创建子进程）；
>- run()：如果没有给定target参数，对这个对象调用start()方法时，就将执行对象中的run()方法，用于继承的时候复写；
>- terminate()：不管任务是否完成，立即终止；
>- name：当前进程实例别名，默认为Process-N，N为从1开始递增的整数；
>- pid：当前进程实例的PID值
>- daemon: 守护进程同多线程的setDaemon()
### 进程间通信-Queue 
>- queue = multiprocessing.Queue(maxsize=-1)  # 创建一个进程队列，maxsize<1的时候 队列长度无限
>>- q.put(item, block=True, timeout=None)
>>> 向队列添加数据，如果block为True则队列满的时候将阻塞，直到队列空出一个数据单元，如果block为False，进程队列满的时候竟引发Full异常, timeout:超时时间
>>- q.put_nowait(item) # 相当于q.put(item, block=False)

>>- q.get(block=True, timeout=None)
>>> 向队列头删除并返回一个数据，block为True时，如果队列为空，则阻塞线程，直到队列中有数据。如果未False，当队列为空的时候竟引发Empty异常 timeout:超时时间
>>- q.get_nowait() # 相当于q.get(block=False)
>>- q.qsize() # 返回队列的大小
>>- q.empty() # 判断队列是否为空，空：True，有：False
>>- q.full() # 判断队列是否满了，满了返回True 反之False
>-  close(self):
>-  join_thread(self):
>-  cancel_join_thread(self)
### 进程间通信-Pip
>- parent, child = multiprocessing.Pipe(): 获取一个双向管道
>>- send(self, obj): # 给管道另一端发送消息
>>- recv(self): # 阻塞进程执行，接受另一端的消息
>>- fileno(self): #
>>- close(self): # 关闭通道
>>- poll(self, timeout=None):
>>- send_bytes(self, buffer, offset=-1, size=-1):
>>- recv_bytes(self, maxlength=-1):
>>- recv_bytes_into(self, buffer, offset=-1):

### 进程间的数据共享-Managers
>- manager = multiprocessing.Managers() # 创建一个共享对象
>- dict = manager.dict() # 创建一个进程间的共享字典
>- list = manager.list() # 创建一个进程间的共享列表
>- manager.close() # 释放资源

### 进程同步锁-Lock
>- lock = multiprocessing.Lock()
>>- lock.acquire() # 上锁
>>- lock.release() # 释放锁

### 进程池- Pool
>当需要创建的子进程数量不多时，可以直接利用multiprocessing中的Process动态成生多个进程，但如果是上百甚至上千个目标，手动的去创建进程的工作量巨大，此时就可以用到multiprocessing模块提供的Pool方法。

>- multiprocessing.Pool常用函数解析：
>- apply(func[, args[, kwds]])：从进程池中取一个进程同步执行
>- apply_async(self, func, args=(), kwds={}, callback=None,error_callback=None): # 从进程池中取一个进程，异步执行
>- close()：关闭Pool，使其不再接受新的任务；
>- terminate()：不管任务是否完成，立即终止；
>- join()：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用；
>- map(self, func, iterable, chunksize=None): Pool类中的map方法，与内置的map函数用法行为基本一致，它会使进程阻塞直到返回结果。
注意，虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程。
>- starmap(self, func, iterable, chunksize=None):
>- starmap_async(self, func, iterable, chunksize=None, callback=None, error_callback=None):
>- imap(self, func, iterable, chunksize=1):
>- imap_unordered(self, func, iterable, chunksize=1):
>- map_async(self, func, iterable, chunksize=None, callback=None,


### Process实现抽屉全站点赞
```
import requests
from bs4 import BeautifulSoup
import queue
import multiprocessing
import sys


class Chouti(object):

    def __init__(self, phone, password):
        '''分析：
            1. 抽屉需要先发送一个get请求，获取gpsd
            2.携带第一次get请求获取的gpsd，去登录验证
            3.携带第一次get请求的gpsd去点赞
            :param phone: 抽屉手机号，需要86开头
            :param password: 抽屉登录密码'''

        self._login_post_date = {
            'phone': phone,
            'password': password,
            'oneMonth': 1}
        self._headers = {
            'Origin': 'http://dig.chouti.com',
            'Referer': 'http://dig.chouti.com/',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 UBrowser/6.2.3964.2 Safari/537.36'
        }
        self.session = requests.Session()
        self.num_q = multiprocessing.Queue() # 存放页码
        self.links_q = multiprocessing.Queue()  # 存放linksid
        self.event = multiprocessing.Event()  # 创建event对象用于让主线程推出

    # 登录抽屉，并初始化num_q这个页码队列
    def login(self):
        self.session.get(url='http://dig.chouti.com/', headers=self._headers)
        self.session.post(url='http://dig.chouti.com/login', data=self._login_post_date, headers=self._headers, )
        for i in range(1, 121):
            self.num_q.put(i)

    # 获取每个新闻的linksid放入队列中
    def get_respones(self):
        while True:
            if not self.num_q.empty():  # 判断页码队列是否为空
                respones = self.session.get(url='http://dig.chouti.com/all/hot/recent/%s' % self.num_q.get(), headers=self._headers)
                soup = BeautifulSoup(respones.text, 'lxml')
                news_div = soup.find(id='content-list')
                news_list = news_div.find_all('div', attrs={'class': 'item'})
                for i in news_list:
                    news_id = i.find('i')
                    self.links_q.put(news_id.text)
            else:
                break

    # 推荐函数
    def recommend(self):
        while True:
            try:
                text =self.session.post(url='http://dig.chouti.com/link/vote?linksId=%s' % self.links_q.get(timeout=10), headers=self._headers)
                print(text.text)
            except queue.Empty:
                self.event.set()

    # 取消推荐
    def cancel_recommend(self):
        while True:
            try:
                text =self.session.post(url='http://dig.chouti.com/vote/cancel/vote.do', data={'linksId': self.links_q.get(timeout=10)} ,headers=self._headers)
                print(text.text)
            except queue.Empty:
                self.event.set()

    # 终极版本，使用Session 管理cookie
    def start_v2(self):
        self.login()
        for i in range(100):
            process = multiprocessing.Process(target=self.get_respones)
            process.daemon = True
            process.start()
        for i in range(100):
            process = multiprocessing.Process(target=self.cancel_recommend)
            process.daemon = True
            process.start()
        self.event.wait()
        print('操作完毕')
        sys.exit()


if __name__ == '__main__':
    c = Chouti(phone='username', password='passwd')
    c.start_v2()

```

### 进程池Pool 实现抽屉新热榜全站自动点赞
```
import requests
from bs4 import BeautifulSoup
import queue
import multiprocessing


class Chouti(object):

    def __init__(self, phone, password):
        '''分析：
            1. 抽屉需要先发送一个get请求，获取gpsd
            2.携带第一次get请求获取的gpsd，去登录验证
            3.携带第一次get请求的gpsd去点赞
            :param phone: 抽屉手机号，需要86开头
            :param password: 抽屉登录密码'''

        self._login_post_date = {
            'phone': phone,
            'password': password,
            'oneMonth': 1}
        self._headers = {
            'Origin': 'http://dig.chouti.com',
            'Referer': 'http://dig.chouti.com/',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 UBrowser/6.2.3964.2 Safari/537.36'
        }
        self.session = requests.Session()
        self.num_q = multiprocessing.Manager().Queue() # 存放页码
        self.links_q = multiprocessing.Manager().Queue()  # 存放linksid
        self.event = multiprocessing.Manager().Event()  # 创建event对象用于让主线程推出

    # 登录抽屉，并初始化num_q这个页码队列
    def login(self):
        self.session.get(url='http://dig.chouti.com/', headers=self._headers)
        login = self.session.post(url='http://dig.chouti.com/login', data=self._login_post_date, headers=self._headers, )
        print(login.text)
        for i in range(1, 121):
            self.num_q.put(i)

    # 获取每个新闻的linksid放入队列中
    def get_respones(self, num_q=None, links_q=None):
        if not num_q:
            num_q = self.num_q
        if not links_q:
            links_q = self.links_q
        while True:
            if not num_q.empty():  # 判断页码队列是否为空
                a = num_q.get()
                respones = self.session.get(url='http://dig.chouti.com/all/hot/recent/%s' % a, headers=self._headers)
                soup = BeautifulSoup(respones.text, 'lxml')
                news_div = soup.find(id='content-list')
                news_list = news_div.find_all('div', attrs={'class': 'item'})
                for i in news_list:
                    news_id = i.find('i')
                    links_q.put(news_id.text)
            else:
                break

    # 推荐函数
    def recommend(self, links_q=None, event=None):
        if not links_q:
            links_q = self.links_q
        if not event:
            event = self.event
        while True:
            try:
                text =self.session.post(url='http://dig.chouti.com/link/vote?linksId=%s' % links_q.get(timeout=10), headers=self._headers)
                print(text.text)
            except queue.Empty:
                event.set()

    # 取消推荐
    def cancel_recommend(self, links_q=None, event=None):
        if not links_q:
            links_q = self.links_q
        if not event:
            event = self.event
        while True:
            try:
                text =self.session.post(url='http://dig.chouti.com/vote/cancel/vote.do', data={'linksId': links_q.get(timeout=10)} ,headers=self._headers)
                print(text.text)
            except queue.Empty:
                event.set()

    # 终极版本，使用Session 管理cookie
    def start_v2(self):
        self.login()
        pool = multiprocessing.Pool(200)

        for i in range(100):
            pool.apply_async(func=self.get_respones, args=(self.num_q,  self.links_q))
        for i in range(100):
            pool.apply_async(func=self.cancel_recommend, args=(self.links_q, self.event))
        print(1)
        self.event.wait()
        pool.terminate()
        print('操作完毕')


if __name__ == '__main__':
    c = Chouti(phone='8617612226296', password='wangyaojie150300')
    c.start_v2()

```
